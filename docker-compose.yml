services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 5s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia

  api:
    build:
      context: ./api
    ports:
      - "8000:8000"
    depends_on:
      ollama:
        condition: service_healthy
    restart: always

  frontend:
    build:
      context: ./frontend
    ports:
      - "8501:8501"
    depends_on:
      - api
    restart: always

  #test:
  #  build:
  #    context: ./api
  #  command: pytest /app/api/tests
  #  volumes:
  #    - .:/app
  #  depends_on:
  #    - api

volumes:
  ollama_models:
